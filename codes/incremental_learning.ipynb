{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d72861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae69e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_learning_model(input_shape):\n",
    "    \"\"\"Creates and compiles the Deep Learning model.\"\"\"\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(input_shape,)),\n",
    "            layers.Dense(50, activation=\"relu\"),\n",
    "            layers.Dense(50, activation=\"relu\"),\n",
    "            layers.Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"Nadam\", loss=\"binary_crossentropy\", metrics=[keras.metrics.AUC(name=\"auc_score\")])\n",
    "    return model\n",
    "\n",
    "def load_dataset(file_paths, separator=\";\"):\n",
    "    \"\"\"Loads, concatenates and shuffles datasets.\"\"\"\n",
    "    df_list = [pd.read_csv(f, sep=separator) for f in file_paths]\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    combined_df = combined_df.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    X = combined_df.drop(columns=[\"label\"])\n",
    "    y = combined_df[\"label\"]\n",
    "    return X, y\n",
    "\n",
    "def calculate_all_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates and returns the confusion matrix, accuracy, and other key metrics.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    ar = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return ar, precision, recall, f1, cm\n",
    "\n",
    "def print_results(model_name, ar, duration, precision, recall, f1):\n",
    "    \"\"\"Prints the calculated metrics and training duration.\"\"\"\n",
    "    print(f\"--- {model_name} Results ---\")\n",
    "    print(f\"Accuracy Rate: {ar:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"Training Duration: {duration} ms\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "def get_f1(model, X, y, is_dl=False):\n",
    "    \"\"\"Calculates F1 score for evaluation.\"\"\"\n",
    "    if is_dl:\n",
    "        y_pred = (model.predict(X) > 0.45).astype(int)\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "    # Note: Ensure calculate_all_metrics returns (ar, precision, recall, f1, cm)\n",
    "    _, _, _, f1, _ = calculate_all_metrics(y, y_pred)\n",
    "    return round(f1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62644ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_files = [\n",
    "    \"../datasets/HelloFloodAttack.csv\", \"../datasets/DecreasedRankAttack.csv\"\n",
    "]\n",
    "finetune_files = [\n",
    "    \"../datasets/VersionNumberAttack.csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76849ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 440us/step\n",
      "13/13 [==============================] - 0s 515us/step\n",
      "31/31 [==============================] - 0s 446us/step\n",
      "13/13 [==============================] - 0s 507us/step\n",
      "\n",
      "====================================================================================================\n",
      "FINAL PERFORMANCE AND TIMING MATRIX\n",
      "====================================================================================================\n",
      "        Model  Pre_Time(ms)  FT_Time(ms)  PreData_BeforeFT  PreData_AfterFT  FTData_BeforeFT  FTData_AfterFT\n",
      "      XGBoost         20.02        20.27            0.9668           0.9238           0.6163          0.9398\n",
      "     LightGBM         14.64         9.98            0.9485           0.9171           0.8358          0.9375\n",
      "     CatBoost          6.99         5.01            0.9601           0.9183           0.7290          0.9333\n",
      "Deep Learning       2255.80       356.91            0.9123           0.9096           0.8344          0.9291\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "X_pre_full, y_pre_full = load_dataset(pretrain_files)\n",
    "X_ft_full, y_ft_full = load_dataset(finetune_files)\n",
    "\n",
    "# Splitting Data\n",
    "X_pre_train, X_pre_test, y_pre_train, y_pre_test = train_test_split(\n",
    "    X_pre_full, y_pre_full, test_size=0.3, random_state=13, stratify=y_pre_full\n",
    ")\n",
    "X_ft_train, X_ft_test, y_ft_train, y_ft_test = train_test_split(\n",
    "    X_ft_full, y_ft_full, test_size=0.3, random_state=13, stratify=y_ft_full\n",
    ")\n",
    "\n",
    "# Normalization\n",
    "scaler = Normalizer()\n",
    "cols_to_norm = X_pre_train.columns[2:].tolist()\n",
    "X_pre_train[cols_to_norm] = scaler.fit_transform(X_pre_train[cols_to_norm])\n",
    "X_pre_test[cols_to_norm] = scaler.transform(X_pre_test[cols_to_norm])\n",
    "X_ft_train[cols_to_norm] = scaler.transform(X_ft_train[cols_to_norm])\n",
    "X_ft_test[cols_to_norm] = scaler.transform(X_ft_test[cols_to_norm])\n",
    "\n",
    "# Model Definitions\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier(max_depth=3, n_estimators=10, random_state=3),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(max_depth=3, n_estimators=8, random_state=3, verbosity=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(max_depth=3, n_estimators=8, random_state=3, verbose=0),\n",
    "    \"Deep Learning\": create_deep_learning_model(X_pre_train.shape[1])\n",
    "}\n",
    "\n",
    "detailed_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    is_dl = (name == \"Deep Learning\")\n",
    "\n",
    "    # --- PRE-TRAINING ---\n",
    "    start_pre = time.time()\n",
    "    if is_dl:\n",
    "        model.fit(X_pre_train, y_pre_train, epochs=50, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_pre_train, y_pre_train)\n",
    "    time_pre = (time.time() - start_pre) * 1000\n",
    "\n",
    "    # Scores Before Fine-Tuning\n",
    "    pre_f1_before = get_f1(model, X_pre_test, y_pre_test, is_dl)\n",
    "    ft_f1_before  = get_f1(model, X_ft_test, y_ft_test, is_dl)\n",
    "\n",
    "    # --- FINE-TUNING ---\n",
    "    start_ft = time.time()\n",
    "    if is_dl:\n",
    "        model.fit(X_ft_train, y_ft_train, epochs=20, verbose=0)\n",
    "    elif \"XGBoost\" in name:\n",
    "        model.fit(X_ft_train, y_ft_train, xgb_model=model)\n",
    "    else:\n",
    "        model.fit(X_ft_train, y_ft_train, init_model=model)\n",
    "    time_ft = (time.time() - start_ft) * 1000\n",
    "\n",
    "    # Scores After Fine-Tuning\n",
    "    pre_f1_after = get_f1(model, X_pre_test, y_pre_test, is_dl)\n",
    "    ft_f1_after  = get_f1(model, X_ft_test, y_ft_test, is_dl)\n",
    "\n",
    "    detailed_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Pre_Time(ms)\": round(time_pre, 2),\n",
    "        \"FT_Time(ms)\": round(time_ft, 2),\n",
    "        \"PreData_BeforeFT\": pre_f1_before,\n",
    "        \"PreData_AfterFT\": pre_f1_after,\n",
    "        \"FTData_BeforeFT\": ft_f1_before,\n",
    "        \"FTData_AfterFT\": ft_f1_after\n",
    "    })\n",
    "\n",
    "# --- Final Performance & Timing Report ---\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL PERFORMANCE AND TIMING MATRIX\")\n",
    "print(\"=\"*100)\n",
    "summary_df = pd.DataFrame(detailed_results)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e2e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
